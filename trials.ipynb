{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pinecone\n",
    "from dotenv import load_dotenv\n",
    "from langchain.agents import AgentType\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import PythonLoader\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import Language, RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Pinecone\n",
    "from langchain_experimental.agents.agent_toolkits import create_python_agent\n",
    "from langchain_experimental.tools import PythonREPLTool\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "# initialize Vector DB\n",
    "pinecone.init(\n",
    "    api_key=os.environ.get(\"PINECONE_API_KEY\"),\n",
    "    environment=os.environ.get(\"PINECONE_ENV\"),\n",
    ")\n",
    "\n",
    "# set Index Params\n",
    "# note: dimension of the index is found from the embeddings model\n",
    "# site: https://platform.openai.com/docs/guides/embeddings/what-are-embeddings\n",
    "# model: text-embedding-ada-002\n",
    "\n",
    "index_name = \"ai-developer\"\n",
    "index_dim = 1536\n",
    "index_metric = \"euclidean\"\n",
    "\n",
    "if index_name in pinecone.list_indexes():\n",
    "    index = pinecone.Index(index_name)\n",
    "\n",
    "    # if the vectors are present in index - clean up & create a new index\n",
    "    # no better way due to free tier\n",
    "    if index.describe_index_stats()[\"total_vector_count\"] > 0:\n",
    "        pinecone.delete_index(name=index_name)\n",
    "        pinecone.create_index(name=index_name, dimension=index_dim, metric=index_metric)\n",
    "    else:\n",
    "        pass\n",
    "else:\n",
    "    # if index not present - create one\n",
    "    pinecone.create_index(name=index_name, dimension=index_dim, metric=index_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the file\n",
    "loader = PythonLoader(\"load_py_file.py\")\n",
    "document = loader.load()\n",
    "\n",
    "# split the file (note: previously used CharacterTextSplitter but it does not take language into account)\n",
    "python_splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "    language=Language.PYTHON, chunk_size=300, chunk_overlap=10\n",
    ")\n",
    "python_docs = python_splitter.split_documents(document)\n",
    "\n",
    "print(f\"Number of documets after the split on chunks: {len(python_docs)}\")\n",
    "\n",
    "# create embeddings\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
    "docsearch = Pinecone.from_documents(python_docs, embeddings, index_name=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define RetrievalQA model (previsouly used VectorDBQA, but got deprecated)\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=ChatOpenAI(model_name=\"gpt-3.5-turbo-16k\"),\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=docsearch.as_retriever(),\n",
    "    verbose=True,\n",
    "    return_source_documents=True,\n",
    ")\n",
    "\n",
    "# define the python agent\n",
    "python_agent_executor = create_python_agent(\n",
    "    llm=ChatOpenAI(temperature=0, model=\"gpt-4\"),\n",
    "    tool=PythonREPLTool(),\n",
    "    agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True,  # retries on failed parsing at the first attempt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### running agents separately\n",
    "\n",
    "\n",
    "# define the error and the query\n",
    "error = \"TypeError: can only concatenate str (not 'list') to str\"\n",
    "query = f\"When running the code base script I get the error {error}.\\\n",
    "    Code base is in the vector database, you can look it up there.\\\n",
    "    Adjust the code to resolve this issue.\"\n",
    "\n",
    "result = qa(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the output of running the model above\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_python = f\"You are given these document: {result['source_documents']}.\\\n",
    "                You need to change the code for the relevant document from all documents provided given these instructions: {result['result']}.\\\n",
    "                You need to make sure to process the document and instructions from text format into the python code.\\\n",
    "                Action: Save this new processed code in current working directory, name the file solution and use expension.py\"\n",
    "python_agent_executor.run(query_python)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useful links:\n",
    "- [Python Code Split](https://python.langchain.com/docs/modules/data_connection/document_transformers/text_splitters/code_splitter)\n",
    "- [OpenAI Embeddings](https://platform.openai.com/docs/guides/embeddings/what-are-embeddings)\n",
    "- Might be interesting for tool routing for later on: [Agent & Retrieval QA](https://stackoverflow.com/questions/77178370/how-to-retrieve-source-documents-via-langchains-get-relevant-documents-method-o) \n",
    "- The {context} needs to be added to the comment though [Prompt Template & Retrieval QA](https://stackoverflow.com/questions/76554411/unable-to-pass-prompt-template-to-retrievalqa-in-langchain)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-developer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
